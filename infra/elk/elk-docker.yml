version: "3.7"

services:

  logstash:
    image: docker.elastic.co/logstash/logstash:8.2.0
    container_name: logstash
    restart: unless-stopped
    volumes:
      - "./elk/config/logstash.conf:/usr/share/logstash/pipeline/logstash.conf:ro"
    depends_on:
      - elasticsearch
    networks:
      - ${GLOBAL_NETWORK:-kafka}

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.2.0
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - ./volumes/elasticsearch/data:/usr/share/elasticsearch/data
    restart: unless-stopped
    ports:
      - "9200:9200"
      - "9300:9300"
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "curl --fail http://localhost:9200 || exit 1",
        ]
      interval: 10s
      timeout: 10s
      retries: 120
    networks:
      - ${GLOBAL_NETWORK:-kafka}

  kibana:
    container_name: kibana
    image: docker.elastic.co/kibana/kibana:8.2.0
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    restart: unless-stopped
    ports:
      - "5601:5601"
    depends_on:
      - elasticsearch
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "curl --fail http://localhost:5601 || exit 1",
        ]
      interval: 10s
      timeout: 10s
      retries: 120
    networks:
      - ${GLOBAL_NETWORK:-kafka}